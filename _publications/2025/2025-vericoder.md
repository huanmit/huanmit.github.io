---
title:          "VeriCoder: Enhancing LLM-Based RTL Code Generation through Functional Correctness Validation"
date:           2025-06-15 00:00:00 +0800
selected:       true
pub:            "NuerIPS 2025 Fourth Workshop on Deep Learning for Code"
# pub_pre:        "arXiv:"
# pub_post:       "2504.15659"
# pub_pre:        "Submitted to "
# pub_post:       ' Under review.'
pub_date:       "2025"

abstract: >-
  VeriCoder is a model for RTL (Register Transfer Level) code generation, fine-tuned on a novel dataset that is functionally validated via feedback-directed refinement. Unlike prior datasets that only ensure syntactic correctness, our dataset guarantees that each RTL design passes automatically generated unit tests aligned with its natural language specification. Our key contributions include: (1) a large-scale dataset of 125,000+ examples with simulation-passing RTL designs, (2) a feedback-driven construction methodology that iteratively refines designs and tests based on test results, (3) superior performance with up to +71.7% relative improvement on VerilogEval benchmarks, and (4) comprehensive resources including dataset, model weights, inference scripts, and training pipeline.
cover: /assets/images/covers/vericoder.png
authors:
  - Anjiang Wei
  - "<strong>Huanmi Tan</strong>"
  - Tarun Suresh
  - Daniel Mendoza
  - Thiago SFX Teixeira
  - Ke Wang
  - Caroline Trippel
  - Alex Aiken
links:
  arXiv: https://arxiv.org/abs/2504.15659
---
